---
title: Introduction
description: Welcome to the Ultimate AI-Powered Documentation Starter
---

# VectraDocs

**VectraDocs** is a next-generation documentation starter kit designed to provide a premium, AI-native experience out of the box. Built on top of **Next.js 16**, **Fumadocs**, **LangChain**, and **Orama**, it combines a beautiful UI with powerful client-side RAG (Retrieval-Augmented Generation) search.

## Why "VectraDocs"?

Traditional documentation sites are static. Users search for keywords and hope for matches. **VectraDocs** changes the game by embedding a context-aware AI Assistant directly into the reading experience.

### Key Features

- **üß† Context-Aware AI Chat**: An intelligent assistant that reads your documentation and answers user questions instantly.
- **‚ö° Client-Side RAG**: Powered by [Orama](https://askorama.ai/), search indexing happens at build time and runs incredibly fast in the browser or edge.
- **üí¨ Premium UI Experience**:
    - **Floating Action Bar**: A sleek, non-intrusive input bar that expands as you type.
    - **Rich Markdown Rendering**: The chat supports code blocks, bold text, lists, and links.
    - **Code Copying**: One-click copy for all code snippets generated by the AI.
- **üõ†Ô∏è Easy Configuration**: Precise control over the System Prompt, LLM Model (OpenAI, Ollama, Anthropic), and UI styling.
- **üöÄ Next.js 16 & React 19**: Built on the bleeding edge for maximum performance.

## VitePress Plugin

Using VitePress instead of Next.js? We have an npm package for that!

```bash
npm install vetradocs-vitepress
```

**[View on npm ‚Üí](https://www.npmjs.com/package/vetradocs-vitepress)** | **[Plugin GitHub](https://github.com/iotserver24/vetradocs-vitepress)**

The VitePress plugin provides the same AI chat experience with:
- Vue 3 components (`VetradocsChat`, `VetradocsFloatingBar`)
- Vue composable (`useVetradocs`) for custom implementations
- CLI tool for building the search index: `npx vetradocs-build`

## Architecture

1.  **Ingestion (`scripts/build-index.mjs`)**: Scans your `.mdx` files at build time and creates a search index.
2.  **Storage**: The index is saved as a JSON file in `public/search-index.json`.
3.  **Retrieval (`app/api/chat/route.ts`)**: When a user asks a question, the API loads the index, finds relevant docs, and feeds them to the LLM.
4.  **Generation**: The LLM (via LangChain) generates a streaming response based *only* on your documentation.

## GitHub Repository

**[https://github.com/iotserver24/VectraDocs](https://github.com/iotserver24/VectraDocs)**

## Next Steps

Ready to build? Check out the [Installation Guide](./installation) to get started.
